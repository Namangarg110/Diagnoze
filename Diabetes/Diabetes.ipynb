{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fourth-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satellite-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes75pc_100_times.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "american-glory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50500\n",
       "1    27068\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "personalized-trustee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77568 entries, 0 to 77567\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               77568 non-null  int64  \n",
      " 1   Glucose                   77568 non-null  int64  \n",
      " 2   BloodPressure             77568 non-null  int64  \n",
      " 3   SkinThickness             77568 non-null  int64  \n",
      " 4   Insulin                   77568 non-null  int64  \n",
      " 5   BMI                       77568 non-null  float64\n",
      " 6   DiabetesPedigreeFunction  77568 non-null  float64\n",
      " 7   Age                       77568 non-null  int64  \n",
      " 8   Outcome                   77568 non-null  int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "saving-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coated-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "increased-julian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62054, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frequent-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collect-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "banner-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaled_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "virtual-harmony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.338571</td>\n",
       "      <td>0.092918</td>\n",
       "      <td>0.147859</td>\n",
       "      <td>0.154129</td>\n",
       "      <td>0.278164</td>\n",
       "      <td>-0.617184</td>\n",
       "      <td>-0.696638</td>\n",
       "      <td>-0.276543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253827</td>\n",
       "      <td>-1.082823</td>\n",
       "      <td>0.147859</td>\n",
       "      <td>0.717886</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>0.591661</td>\n",
       "      <td>-0.638609</td>\n",
       "      <td>-0.446725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.338571</td>\n",
       "      <td>0.635567</td>\n",
       "      <td>0.665322</td>\n",
       "      <td>0.342048</td>\n",
       "      <td>1.775991</td>\n",
       "      <td>0.067504</td>\n",
       "      <td>-0.087333</td>\n",
       "      <td>2.106009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.846226</td>\n",
       "      <td>-3.765922</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>-0.033790</td>\n",
       "      <td>-0.492395</td>\n",
       "      <td>-0.470031</td>\n",
       "      <td>-0.522551</td>\n",
       "      <td>-1.042363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253827</td>\n",
       "      <td>-1.806355</td>\n",
       "      <td>0.665322</td>\n",
       "      <td>0.467328</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>-0.696638</td>\n",
       "      <td>1.084916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62049</th>\n",
       "      <td>-1.142425</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>1.079292</td>\n",
       "      <td>1.594842</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>1.231353</td>\n",
       "      <td>-0.290435</td>\n",
       "      <td>-1.042363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62050</th>\n",
       "      <td>-1.142425</td>\n",
       "      <td>-0.510026</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>1.031085</td>\n",
       "      <td>0.589850</td>\n",
       "      <td>0.965017</td>\n",
       "      <td>0.376899</td>\n",
       "      <td>-0.957272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62051</th>\n",
       "      <td>0.634771</td>\n",
       "      <td>-0.962234</td>\n",
       "      <td>-0.369604</td>\n",
       "      <td>0.717886</td>\n",
       "      <td>0.399375</td>\n",
       "      <td>-0.136808</td>\n",
       "      <td>-1.160870</td>\n",
       "      <td>1.084916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62052</th>\n",
       "      <td>0.634771</td>\n",
       "      <td>2.173074</td>\n",
       "      <td>1.182785</td>\n",
       "      <td>-1.286584</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>0.319245</td>\n",
       "      <td>-0.609594</td>\n",
       "      <td>2.786739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62053</th>\n",
       "      <td>-0.550026</td>\n",
       "      <td>-0.510026</td>\n",
       "      <td>-0.369604</td>\n",
       "      <td>-0.660187</td>\n",
       "      <td>1.715385</td>\n",
       "      <td>-0.828793</td>\n",
       "      <td>1.218320</td>\n",
       "      <td>-0.957272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62054 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin  \\\n",
       "0         0.338571  0.092918       0.147859       0.154129  0.278164   \n",
       "1        -0.253827 -1.082823       0.147859       0.717886 -0.691528   \n",
       "2         0.338571  0.635567       0.665322       0.342048  1.775991   \n",
       "3        -0.846226 -3.765922       0.251352      -0.033790 -0.492395   \n",
       "4        -0.253827 -1.806355       0.665322       0.467328 -0.691528   \n",
       "...            ...       ...            ...            ...       ...   \n",
       "62049    -1.142425  0.876745       1.079292       1.594842 -0.691528   \n",
       "62050    -1.142425 -0.510026       0.044366       1.031085  0.589850   \n",
       "62051     0.634771 -0.962234      -0.369604       0.717886  0.399375   \n",
       "62052     0.634771  2.173074       1.182785      -1.286584 -0.691528   \n",
       "62053    -0.550026 -0.510026      -0.369604      -0.660187  1.715385   \n",
       "\n",
       "            BMI  DiabetesPedigreeFunction       Age  \n",
       "0     -0.617184                 -0.696638 -0.276543  \n",
       "1      0.591661                 -0.638609 -0.446725  \n",
       "2      0.067504                 -0.087333  2.106009  \n",
       "3     -0.470031                 -0.522551 -1.042363  \n",
       "4      0.369107                 -0.696638  1.084916  \n",
       "...         ...                       ...       ...  \n",
       "62049  1.231353                 -0.290435 -1.042363  \n",
       "62050  0.965017                  0.376899 -0.957272  \n",
       "62051 -0.136808                 -1.160870  1.084916  \n",
       "62052  0.319245                 -0.609594  2.786739  \n",
       "62053 -0.828793                  1.218320 -0.957272  \n",
       "\n",
       "[62054 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rocky-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(scaled_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "labeled-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.142425</td>\n",
       "      <td>-0.479879</td>\n",
       "      <td>-0.473097</td>\n",
       "      <td>0.279409</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>-0.701098</td>\n",
       "      <td>-1.015797</td>\n",
       "      <td>-0.872181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253827</td>\n",
       "      <td>1.419394</td>\n",
       "      <td>-0.266111</td>\n",
       "      <td>1.031085</td>\n",
       "      <td>1.256513</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>-0.377478</td>\n",
       "      <td>-0.276543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.846226</td>\n",
       "      <td>-0.962234</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>0.655247</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>-0.122214</td>\n",
       "      <td>-0.493536</td>\n",
       "      <td>-0.872181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.550026</td>\n",
       "      <td>0.243654</td>\n",
       "      <td>-0.576589</td>\n",
       "      <td>0.216769</td>\n",
       "      <td>1.689411</td>\n",
       "      <td>-0.423818</td>\n",
       "      <td>3.481451</td>\n",
       "      <td>-0.701999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253827</td>\n",
       "      <td>-1.384294</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>-1.286584</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>-0.073569</td>\n",
       "      <td>-0.580580</td>\n",
       "      <td>0.489278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15509</th>\n",
       "      <td>0.930970</td>\n",
       "      <td>0.575273</td>\n",
       "      <td>1.079292</td>\n",
       "      <td>0.216769</td>\n",
       "      <td>3.464293</td>\n",
       "      <td>-0.286394</td>\n",
       "      <td>-1.044812</td>\n",
       "      <td>0.829642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15510</th>\n",
       "      <td>1.523368</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.872307</td>\n",
       "      <td>0.467328</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.434779</td>\n",
       "      <td>2.204813</td>\n",
       "      <td>0.744551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15511</th>\n",
       "      <td>0.634771</td>\n",
       "      <td>-0.087965</td>\n",
       "      <td>1.389770</td>\n",
       "      <td>-1.286584</td>\n",
       "      <td>-0.691528</td>\n",
       "      <td>-0.409224</td>\n",
       "      <td>-0.957768</td>\n",
       "      <td>-0.276543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15512</th>\n",
       "      <td>1.227169</td>\n",
       "      <td>1.690719</td>\n",
       "      <td>1.079292</td>\n",
       "      <td>0.843166</td>\n",
       "      <td>1.905860</td>\n",
       "      <td>0.283977</td>\n",
       "      <td>-0.029304</td>\n",
       "      <td>2.106009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15513</th>\n",
       "      <td>-0.550026</td>\n",
       "      <td>0.123065</td>\n",
       "      <td>-1.197545</td>\n",
       "      <td>0.028850</td>\n",
       "      <td>2.208889</td>\n",
       "      <td>0.209793</td>\n",
       "      <td>-0.899739</td>\n",
       "      <td>-0.957272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15514 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin  \\\n",
       "0        -1.142425 -0.479879      -0.473097       0.279409 -0.691528   \n",
       "1        -0.253827  1.419394      -0.266111       1.031085  1.256513   \n",
       "2        -0.846226 -0.962234       0.044366       0.655247 -0.691528   \n",
       "3        -0.550026  0.243654      -0.576589       0.216769  1.689411   \n",
       "4        -0.253827 -1.384294       0.044366      -1.286584 -0.691528   \n",
       "...            ...       ...            ...            ...       ...   \n",
       "15509     0.930970  0.575273       1.079292       0.216769  3.464293   \n",
       "15510     1.523368  0.997333       0.872307       0.467328  0.650456   \n",
       "15511     0.634771 -0.087965       1.389770      -1.286584 -0.691528   \n",
       "15512     1.227169  1.690719       1.079292       0.843166  1.905860   \n",
       "15513    -0.550026  0.123065      -1.197545       0.028850  2.208889   \n",
       "\n",
       "            BMI  DiabetesPedigreeFunction       Age  \n",
       "0     -0.701098                 -1.015797 -0.872181  \n",
       "1      0.167228                 -0.377478 -0.276543  \n",
       "2     -0.122214                 -0.493536 -0.872181  \n",
       "3     -0.423818                  3.481451 -0.701999  \n",
       "4     -0.073569                 -0.580580  0.489278  \n",
       "...         ...                       ...       ...  \n",
       "15509 -0.286394                 -1.044812  0.829642  \n",
       "15510  0.434779                  2.204813  0.744551  \n",
       "15511 -0.409224                 -0.957768 -0.276543  \n",
       "15512  0.283977                 -0.029304  2.106009  \n",
       "15513  0.209793                 -0.899739 -0.957272  \n",
       "\n",
       "[15514 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "based-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sacred-helmet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wrong-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "victorian-spider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fiscal-plain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998710841820291"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accessible-structure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10143,     0],\n",
       "       [    2,  5369]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "native-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "armed-pattern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "changing-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_f = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "valid-venice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "active-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10143,     0],\n",
       "       [    0,  5371]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(random_state=10)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_s = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numbers before smote\n",
    "num_before = dict(Counter(y))\n",
    "\n",
    "#perform smoting\n",
    "\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.8)\n",
    "under = RandomUnderSampler(sampling_strategy=0.8)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_smote, y_smote = pipeline.fit_resample(X, y)\n",
    "\n",
    "\n",
    "#the numbers after smote\n",
    "num_after =dict(Counter(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaled_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(scaled_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_s = RandomForestClassifier(random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_s.fit(X_train, y_train)\n",
    "pred_s = forest_s.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-colonial",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adequate-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "moral-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "assumed-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exterior-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.5120 - accuracy: 0.7405\n",
      "Epoch 2/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.4163 - accuracy: 0.8020\n",
      "Epoch 3/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.3926 - accuracy: 0.8090\n",
      "Epoch 4/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.3586 - accuracy: 0.8268\n",
      "Epoch 5/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.3437 - accuracy: 0.8346\n",
      "Epoch 6/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.3266 - accuracy: 0.8462\n",
      "Epoch 7/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.3142 - accuracy: 0.8575\n",
      "Epoch 8/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.3055 - accuracy: 0.8626\n",
      "Epoch 9/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2926 - accuracy: 0.8687\n",
      "Epoch 10/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.2824 - accuracy: 0.8729\n",
      "Epoch 11/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2737 - accuracy: 0.8770\n",
      "Epoch 12/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.2623 - accuracy: 0.8858\n",
      "Epoch 13/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.2552 - accuracy: 0.8885: 0s - loss: 0.2554 \n",
      "Epoch 14/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.2465 - accuracy: 0.8939\n",
      "Epoch 15/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.2380 - accuracy: 0.8979\n",
      "Epoch 16/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.2347 - accuracy: 0.8997\n",
      "Epoch 17/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2265 - accuracy: 0.9057\n",
      "Epoch 18/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2212 - accuracy: 0.9081\n",
      "Epoch 19/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2173 - accuracy: 0.9114\n",
      "Epoch 20/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2090 - accuracy: 0.9156\n",
      "Epoch 21/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2054 - accuracy: 0.9180\n",
      "Epoch 22/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.2029 - accuracy: 0.9186\n",
      "Epoch 23/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1973 - accuracy: 0.9214\n",
      "Epoch 24/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1917 - accuracy: 0.9243\n",
      "Epoch 25/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1893 - accuracy: 0.9250\n",
      "Epoch 26/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1847 - accuracy: 0.9254\n",
      "Epoch 27/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1813 - accuracy: 0.9271\n",
      "Epoch 28/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1792 - accuracy: 0.9299\n",
      "Epoch 29/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1760 - accuracy: 0.9302\n",
      "Epoch 30/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1766 - accuracy: 0.9291\n",
      "Epoch 31/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1680 - accuracy: 0.9337\n",
      "Epoch 32/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1658 - accuracy: 0.9347\n",
      "Epoch 33/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1671 - accuracy: 0.9351\n",
      "Epoch 34/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1634 - accuracy: 0.9352\n",
      "Epoch 35/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1616 - accuracy: 0.9363\n",
      "Epoch 36/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1567 - accuracy: 0.9389\n",
      "Epoch 37/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1609 - accuracy: 0.9367\n",
      "Epoch 38/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1559 - accuracy: 0.9391\n",
      "Epoch 39/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1532 - accuracy: 0.9383\n",
      "Epoch 40/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1520 - accuracy: 0.9405\n",
      "Epoch 41/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1518 - accuracy: 0.9389\n",
      "Epoch 42/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1515 - accuracy: 0.9411\n",
      "Epoch 43/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1450 - accuracy: 0.9424\n",
      "Epoch 44/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1435 - accuracy: 0.9426\n",
      "Epoch 45/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1479 - accuracy: 0.9401\n",
      "Epoch 46/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1467 - accuracy: 0.9383\n",
      "Epoch 47/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1447 - accuracy: 0.9416\n",
      "Epoch 48/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1420 - accuracy: 0.9429\n",
      "Epoch 49/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1407 - accuracy: 0.9441\n",
      "Epoch 50/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1386 - accuracy: 0.9439\n",
      "Epoch 51/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1409 - accuracy: 0.9430\n",
      "Epoch 52/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1398 - accuracy: 0.9439\n",
      "Epoch 53/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1362 - accuracy: 0.9445\n",
      "Epoch 54/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1336 - accuracy: 0.9475\n",
      "Epoch 55/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1324 - accuracy: 0.9464\n",
      "Epoch 56/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1325 - accuracy: 0.9478\n",
      "Epoch 57/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1356 - accuracy: 0.9460\n",
      "Epoch 58/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1308 - accuracy: 0.9474\n",
      "Epoch 59/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1310 - accuracy: 0.9459\n",
      "Epoch 60/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1313 - accuracy: 0.9468\n",
      "Epoch 61/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1293 - accuracy: 0.9495\n",
      "Epoch 62/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1291 - accuracy: 0.9479\n",
      "Epoch 63/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1297 - accuracy: 0.9474\n",
      "Epoch 64/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1278 - accuracy: 0.9492\n",
      "Epoch 65/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1280 - accuracy: 0.9484\n",
      "Epoch 66/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1275 - accuracy: 0.9491\n",
      "Epoch 67/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1262 - accuracy: 0.9500\n",
      "Epoch 68/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1229 - accuracy: 0.9520\n",
      "Epoch 69/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1228 - accuracy: 0.9519\n",
      "Epoch 70/100\n",
      "1940/1940 [==============================] - 4s 2ms/step - loss: 0.1204 - accuracy: 0.9533\n",
      "Epoch 71/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1193 - accuracy: 0.9549\n",
      "Epoch 72/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1181 - accuracy: 0.9543\n",
      "Epoch 73/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1165 - accuracy: 0.9564\n",
      "Epoch 74/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1167 - accuracy: 0.9549\n",
      "Epoch 75/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1138 - accuracy: 0.9578\n",
      "Epoch 76/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1128 - accuracy: 0.9572\n",
      "Epoch 77/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1121 - accuracy: 0.9596\n",
      "Epoch 78/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1106 - accuracy: 0.9602\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1079 - accuracy: 0.9595\n",
      "Epoch 80/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1059 - accuracy: 0.9605\n",
      "Epoch 81/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.1068 - accuracy: 0.9612\n",
      "Epoch 82/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1068 - accuracy: 0.9612\n",
      "Epoch 83/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1058 - accuracy: 0.9615\n",
      "Epoch 84/100\n",
      "1940/1940 [==============================] - 3s 2ms/step - loss: 0.1041 - accuracy: 0.9636\n",
      "Epoch 85/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.0998 - accuracy: 0.9651\n",
      "Epoch 86/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0997 - accuracy: 0.9641\n",
      "Epoch 87/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.0996 - accuracy: 0.9644\n",
      "Epoch 88/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.0967 - accuracy: 0.9661\n",
      "Epoch 89/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.1005 - accuracy: 0.9644\n",
      "Epoch 90/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0969 - accuracy: 0.9651\n",
      "Epoch 91/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0948 - accuracy: 0.9660\n",
      "Epoch 92/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0945 - accuracy: 0.9659\n",
      "Epoch 93/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0929 - accuracy: 0.9677\n",
      "Epoch 94/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0911 - accuracy: 0.9675: 0s - los\n",
      "Epoch 95/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0947 - accuracy: 0.9671\n",
      "Epoch 96/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0929 - accuracy: 0.9671\n",
      "Epoch 97/100\n",
      "1940/1940 [==============================] - 2s 1ms/step - loss: 0.0902 - accuracy: 0.9683\n",
      "Epoch 98/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.0915 - accuracy: 0.9671\n",
      "Epoch 99/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.0893 - accuracy: 0.9698\n",
      "Epoch 100/100\n",
      "1940/1940 [==============================] - 3s 1ms/step - loss: 0.0881 - accuracy: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f97280e6400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "focal-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "competitive-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.round(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "greater-tobago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708650251385845"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "finite-associate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9943,  200],\n",
       "       [ 252, 5119]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "destroyed-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "reserved-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"NN_Weight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-hughes",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "stopped-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "removed-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_train, y_train)\n",
    "pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-dressing",
   "metadata": {},
   "source": [
    "### Ensemble All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "informational-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acceptable-occasions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=10)),\n",
       "                             ('rf', RandomForestClassifier(random_state=10)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=10))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_reg), ('rf', forest),('dt', tree)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "engaged-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "social-opera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998710841820291"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "choice-classroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10143,     0],\n",
       "       [    2,  5369]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
